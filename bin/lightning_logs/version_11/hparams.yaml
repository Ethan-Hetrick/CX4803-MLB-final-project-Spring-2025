batch_normalization: true
hidden_activation: relu
kmer: 7
latent_dim: 128
learning_rate: 0.001
num_classes: 104
